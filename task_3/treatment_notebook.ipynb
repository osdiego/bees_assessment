{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Background schemas are equal? Answer: False\n",
      "The columns in the mapping represents all the mismatched columns in background DataFrames: True\n",
      "Logs schemas are equal? Answer: True\n",
      "{'Demale', 'Female', 'Other', 'Male'}\n",
      "{'Female', 'Other', 'Male'}\n",
      "['FR', 'MX', 'South Africa', 'UK', 'US', 'United Kingdom', 'ZA']\n",
      "['FR', 'GB', 'MX', 'US', 'ZA']\n",
      "The end.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sbees.insecure import (clean_braces, clean_dict_column,\n",
    "                            remove_duplicated_values)\n",
    "from sbees.secure import (clean_columns_values, concat_dataframes, \n",
    "                          fix_country_columns, merge_string_columns)\n",
    "\n",
    "# Configure the settings of pandas so the DataFrames can be better printed\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('max_colwidth', 400)\n",
    "\n",
    "# ||| Step 1 |||: read csv files into pandas DataFrames to better understanding\n",
    "# To run the script inside the task_1 folder\n",
    "assets_folder = '../assets/'\n",
    "# to run it directly on the root folder\n",
    "# assets_folder = './assets/'\n",
    "\n",
    "df_bg_map = pd.read_csv(f'{assets_folder}background_mapping.csv')\n",
    "clean_columns = {c: c.strip() for c in df_bg_map}\n",
    "df_bg_map.rename(columns=clean_columns, inplace=True)\n",
    "\n",
    "df_bg_1 = pd.read_csv(\n",
    "    f'{assets_folder}project_1_background.csv', index_col=0)\n",
    "df_bg_2 = pd.read_csv(\n",
    "    f'{assets_folder}project_2_background.csv', index_col=0)\n",
    "\n",
    "df_logs_1 = pd.read_csv(\n",
    "    f'{assets_folder}project_1_logs.csv', index_col=0)\n",
    "df_logs_2 = pd.read_csv(\n",
    "    f'{assets_folder}project_2_logs.csv', index_col=0)\n",
    "\n",
    "# ||| Step 2 |||: check the difference between datasets\n",
    "# Verify the difference between the background df schemas\n",
    "is_bg_schemas_equal = sorted(list(df_bg_1)) == sorted(list(df_bg_2))\n",
    "print(\n",
    "    f'Background schemas are equal? Answer: {is_bg_schemas_equal}')\n",
    "\n",
    "bg1_not_in_bg2 = sorted([c for c in df_bg_1 if c not in df_bg_2])\n",
    "bg2_not_in_bg1 = sorted([c for c in df_bg_2 if c not in df_bg_1])\n",
    "\n",
    "# Verify that the difference between dfs are the ones in the mapping\n",
    "prj_2_cols = sorted(df_bg_map['Project 1 Question'].values.tolist())\n",
    "is_prj_2_cols_mapped = prj_2_cols == bg2_not_in_bg1\n",
    "prj_1_cols = sorted(df_bg_map['Project 2 Question'].values.tolist())\n",
    "is_prj_1_cols_mapped = prj_1_cols == bg1_not_in_bg2\n",
    "\n",
    "# and that the columns in the mapping file are indeed switched\n",
    "is_all_columns_mapped = is_prj_2_cols_mapped and is_prj_1_cols_mapped\n",
    "print(\n",
    "    'The columns in the mapping represents all the mismatched columns' +\n",
    "    f' in background DataFrames: {is_all_columns_mapped}'\n",
    ")\n",
    "\n",
    "# Confirm that the log dfs has the same schema\n",
    "is_logs_schemas_equal = sorted(list(df_logs_1)) == sorted(list(df_logs_2))\n",
    "print(f'Logs schemas are equal? Answer: {is_logs_schemas_equal}')\n",
    "\n",
    "# ||| Step 3 |||: solve problem on column \"level2dish_coded\"\n",
    "'''For performance reasons, it is necessary to do some cleaning on the\n",
    "datasets before doing the merge'''\n",
    "# Check the real problem in the column formatted as dictionary\n",
    "# pprint(sorted(set(df_logs_1['level2dish_coded'].values)))\n",
    "\n",
    "# Extract the desired value from the column\n",
    "df_logs_1 = clean_dict_column(df=df_logs_1, column='level2dish_coded', key='dish')\n",
    "\n",
    "# ||| Step 4 |||: solve problem on column \"questions_135633_and_who_are_you_sharing_your_home_with\"\n",
    "# check the real problem in the column\n",
    "column_135633 = 'questions_135633_and_who_are_you_sharing_your_home_with'\n",
    "# pprint(sorted(set(df_bg_1[column_135633].values)))\n",
    "# not all values has the brace problem, so the function created handles that\n",
    "df_bg_1 = clean_braces(df=df_bg_1, column=column_135633)\n",
    "# pprint(sorted(set(df_bg_1[column_135633].values)))\n",
    "\n",
    "# ||| Step 5 |||: merge DataFrames\n",
    "# the project 2 columns will be used as final column names\n",
    "map_bg_cols = dict(zip(prj_1_cols, prj_2_cols))\n",
    "df_logs = concat_dataframes(df1=df_logs_1, df2=df_logs_2)\n",
    "df_bg = concat_dataframes(\n",
    "    df1=df_bg_1, df2=df_bg_2, rename_cols=map_bg_cols)\n",
    "\n",
    "# ||| Step 6 |||: fix genders spelt / capitalized differently\n",
    "col_gender = 'questions_135556_what_is_your_gender'\n",
    "df_bg = clean_columns_values(df=df_bg, columns=[col_gender])\n",
    "\n",
    "# It shows that \"Demale\" exists, what is clearly a mistake\n",
    "print(set(df_bg[col_gender].values))\n",
    "\n",
    "# And now it is fixed (done in 2 steps to show the error)\n",
    "map_to_replace = {col_gender: {'Demale': 'Female'}}\n",
    "df_bg = clean_columns_values(\n",
    "    df=df_bg, columns=[col_gender], replaces=map_to_replace)\n",
    "print(set(df_bg[col_gender].values))\n",
    "\n",
    "# ||| Step 7 |||: set all location names to codes\n",
    "# 1º: verify the severity of the problem\n",
    "print(sorted(set(df_logs['location_name'].values)))\n",
    "\n",
    "# 2ª: fix the problem - small note on conversion UK -> GB as this is the ISO\n",
    "df_logs = fix_country_columns(df=df_logs, columns=['location_name'])\n",
    "print(sorted(set(df_logs['location_name'].values)))\n",
    "\n",
    "# ||| Step 8 |||: merge duplicated columns\n",
    "# Verify the existence of duplicated columns on the DataFrames\n",
    "# pprint(sorted(set(df_bg.columns)))\n",
    "# pprint(sorted(set(df_logs.columns)))\n",
    "\n",
    "'''This shows that the questions_134999_where_are_you_eating_at_the_moment\n",
    "column is duplicated on df_logs and will need to be merged, and now it can\n",
    "be done'''\n",
    "df_logs = merge_string_columns(\n",
    "    df=df_logs,\n",
    "    column_a='questions_134999_where_are_you_eating_at_the_moment',\n",
    "    column_b='questions_134999_where_are_you_eating_at_the_moment.1')\n",
    "\n",
    "# ||| Step 9 |||: merge duplicated values on specific columns\n",
    "'''\n",
    "First is necessary to understand which columns will need to be cleaned,\n",
    "and for that specific case, as it is going to be a massive cleaning,\n",
    "discover dynamically which columns need it would not be a safe / optimal\n",
    "choice, so the columns that needs the treatment were verified \"simply\" by\n",
    "looking at the data and checking the ones that have an structure of a list.\n",
    "The columns were then mapped and placed into an asset file.\n",
    "'''\n",
    "with open('../task_1/list_like_columns_map.json') as file:\n",
    "    list_like_columns_map = json.load(file)\n",
    "# pprint(list_like_columns_map)\n",
    "\n",
    "df_bg = remove_duplicated_values(\n",
    "    df=df_bg, list_like_columns=list_like_columns_map['background'])\n",
    "\n",
    "df_logs = remove_duplicated_values(\n",
    "    df=df_logs, list_like_columns=list_like_columns_map['logs'])\n",
    "\n",
    "# ||| Step 10 |||: save the DataFrames\n",
    "'''Both DataFrames are too large to print nicely, so they're being saved as\n",
    "XLSX for a better visualization - could be also saved as CSV, Parquet, etc.\n",
    "'''\n",
    "df_bg.to_excel('output/background_dataset.xlsx')\n",
    "df_logs.to_excel('output/logs_dataset.xlsx')\n",
    "\n",
    "print('The end.')\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7307b88a982307dd8325056769723498162fc2b0abaa94503f3c99a51b98cd48"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
